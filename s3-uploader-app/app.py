from flask import Flask, render_template, request, jsonify, flash, redirect, url_for, Response, stream_with_context
import boto3
from botocore.exceptions import ClientError, NoCredentialsError
import os
import uuid
from datetime import datetime, timedelta
import mimetypes
import traceback
import logging
import hashlib
import sqlite3
import secrets
import threading

app = Flask(__name__)
app.secret_key = 'your-secret-key-change-this'

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# AWS S3 ì„¤ì • - ê³ ì •ëœ ë²„í‚·ê³¼ ë¦¬ì „ ì‚¬ìš©
BUCKET_NAME = 'presigned-url-generator-janghwan'
AWS_REGION = 'us-west-2'
DB_FILE = 'file_links.db'

# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
def init_database():
    """SQLite ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS file_links (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            secure_key TEXT UNIQUE NOT NULL,
            s3_key TEXT NOT NULL,
            original_filename TEXT NOT NULL,
            file_size INTEGER NOT NULL,
            content_type TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            expires_at TIMESTAMP NOT NULL,
            download_count INTEGER DEFAULT 0
        )
    ''')
    
    # ì¸ë±ìŠ¤ ìƒì„±
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_secure_key ON file_links(secure_key)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_expires_at ON file_links(expires_at)')
    
    conn.commit()
    conn.close()

def generate_secure_key():
    """ë³´ì•ˆ í‚¤ ìƒì„± (32ìë¦¬ ëœë¤ ë¬¸ìì—´)"""
    return secrets.token_urlsafe(24)  # 32ìë¦¬ URL-safe ë¬¸ìì—´

def store_file_link(s3_key, original_filename, file_size, content_type, expiration_days):
    """íŒŒì¼ ë§í¬ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
    secure_key = generate_secure_key()
    expires_at = datetime.now() + timedelta(days=expiration_days)
    
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    
    try:
        cursor.execute('''
            INSERT INTO file_links 
            (secure_key, s3_key, original_filename, file_size, content_type, expires_at)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (secure_key, s3_key, original_filename, file_size, content_type, expires_at))
        
        conn.commit()
        logger.info(f"íŒŒì¼ ë§í¬ ì €ì¥ ì™„ë£Œ: {secure_key} -> {s3_key}")
        return secure_key
    except Exception as e:
        logger.error(f"íŒŒì¼ ë§í¬ ì €ì¥ ì‹¤íŒ¨: {e}")
        return None
    finally:
        conn.close()

def get_file_info(secure_key):
    """ë³´ì•ˆ í‚¤ë¡œ íŒŒì¼ ì •ë³´ ì¡°íšŒ"""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    
    try:
        cursor.execute('''
            SELECT s3_key, original_filename, file_size, content_type, expires_at, download_count
            FROM file_links 
            WHERE secure_key = ? AND expires_at > datetime('now')
        ''', (secure_key,))
        
        result = cursor.fetchone()
        if result:
            return {
                's3_key': result[0],
                'original_filename': result[1],
                'file_size': result[2],
                'content_type': result[3],
                'expires_at': result[4],
                'download_count': result[5]
            }
        return None
    except Exception as e:
        logger.error(f"íŒŒì¼ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None
    finally:
        conn.close()

def increment_download_count(secure_key):
    """ë‹¤ìš´ë¡œë“œ íšŸìˆ˜ ì¦ê°€"""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    
    try:
        cursor.execute('''
            UPDATE file_links 
            SET download_count = download_count + 1 
            WHERE secure_key = ?
        ''', (secure_key,))
        conn.commit()
    except Exception as e:
        logger.error(f"ë‹¤ìš´ë¡œë“œ íšŸìˆ˜ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    finally:
        conn.close()

def cleanup_expired_links():
    """ë§Œë£Œëœ ë§í¬ ì •ë¦¬"""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    
    try:
        cursor.execute("DELETE FROM file_links WHERE expires_at <= datetime('now')")
        deleted_count = cursor.rowcount
        conn.commit()
        if deleted_count > 0:
            logger.info(f"ë§Œë£Œëœ ë§í¬ {deleted_count}ê°œ ì •ë¦¬ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"ë§Œë£Œëœ ë§í¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    finally:
        conn.close()

# S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„±
try:
    s3_client = boto3.client('s3', region_name=AWS_REGION)
    logger.info(f"S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì™„ë£Œ - ë¦¬ì „: {AWS_REGION}")
except Exception as e:
    logger.error(f"S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
    s3_client = None

def ensure_bucket_exists():
    """S3 ë²„í‚·ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ìƒì„±"""
    if not s3_client:
        logger.error("S3 í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
        
    try:
        # ë²„í‚· ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        s3_client.head_bucket(Bucket=BUCKET_NAME)
        logger.info(f"ë²„í‚· '{BUCKET_NAME}'ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
        return True
    except ClientError as e:
        error_code = int(e.response['Error']['Code'])
        if error_code == 404:
            # ë²„í‚·ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
            try:
                if AWS_REGION == 'us-east-1':
                    s3_client.create_bucket(Bucket=BUCKET_NAME)
                else:
                    s3_client.create_bucket(
                        Bucket=BUCKET_NAME,
                        CreateBucketConfiguration={'LocationConstraint': AWS_REGION}
                    )
                logger.info(f"ë²„í‚· '{BUCKET_NAME}'ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
                return True
            except ClientError as create_error:
                logger.error(f"ë²„í‚· ìƒì„± ì‹¤íŒ¨: {create_error}")
                return False
        else:
            logger.error(f"ë²„í‚· í™•ì¸ ì‹¤íŒ¨: {e}")
            return False
    except NoCredentialsError:
        logger.error("AWS ìê²© ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    except Exception as e:
        logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return False

def upload_file_to_s3(file, filename=None):
    """íŒŒì¼ì„ S3ì— ì—…ë¡œë“œ"""
    if not s3_client:
        logger.error("S3 í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
        
    try:
        # íŒŒì¼ëª… ì²˜ë¦¬ - íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€ë¡œ ì¤‘ë³µ ë°©ì§€
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            original_filename = file.filename
            name, ext = os.path.splitext(original_filename)
            filename = f"{timestamp}_{name}{ext}"
        
        # Content-Type ì„¤ì •
        content_type = mimetypes.guess_type(filename)[0] or 'application/octet-stream'
        
        logger.info(f"íŒŒì¼ ì—…ë¡œë“œ ì‹œì‘: {filename}")
        s3_client.upload_fileobj(
            file,
            BUCKET_NAME,
            filename,
            ExtraArgs={'ContentType': content_type}
        )
        logger.info(f"íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {filename}")
        return filename
    except ClientError as e:
        logger.error(f"íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None
    except Exception as e:
        logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

def generate_presigned_url(filename, expiration_days=7):
    """ë³´ì•ˆ ê°•í™”ëœ Presigned URL ìƒì„± - ê³µìœ  ê°€ëŠ¥"""
    if not s3_client:
        logger.error("S3 í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
        
    try:
        expiration_seconds = expiration_days * 24 * 60 * 60  # ì¼ì„ ì´ˆë¡œ ë³€í™˜
        
        # ë³´ì•ˆ ê°•í™”ëœ presigned URL ìƒì„± (V4 ì„œëª… ì‚¬ìš©)
        response = s3_client.generate_presigned_url(
            'get_object',
            Params={
                'Bucket': BUCKET_NAME, 
                'Key': filename,
                'ResponseContentDisposition': f'attachment; filename="{filename}"'
            },
            ExpiresIn=expiration_seconds,
            HttpMethod='GET'
        )
        
        # URLì—ì„œ ë¯¼ê°í•œ ì •ë³´ ë§ˆìŠ¤í‚¹ (ë¡œê·¸ìš©)
        masked_url = response.split('?')[0] + '?[SECURED_PARAMETERS]'
        logger.info(f"Presigned URL ìƒì„± ì™„ë£Œ: {filename} -> {masked_url}")
        
        return response
    except ClientError as e:
        logger.error(f"Presigned URL ìƒì„± ì‹¤íŒ¨: {e}")
        return None
    except Exception as e:
        logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ URL ìƒì„± ì˜¤ë¥˜: {e}")
        return None

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/upload', methods=['POST'])
def upload_file():
    try:
        logger.info("íŒŒì¼ ì—…ë¡œë“œ ìš”ì²­ ë°›ìŒ")
        
        # ìš”ì²­ ë°ì´í„° ë””ë²„ê¹…
        logger.info(f"Request files keys: {list(request.files.keys())}")
        logger.info(f"Request form keys: {list(request.form.keys())}")
        
        # AWS ìê²© ì¦ëª… í™•ì¸
        if not s3_client:
            logger.error("AWS ìê²© ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return jsonify({'error': 'AWS ìê²© ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. AWS CLIë¥¼ ì„¤ì •í•˜ê±°ë‚˜ í™˜ê²½ ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.'}), 500
        
        # ë‹¤ì¤‘ íŒŒì¼ ì²˜ë¦¬ - 'files' í‚¤ë¡œ ìˆ˜ì •
        files = request.files.getlist('files')
        if not files or all(file.filename == '' for file in files):
            logger.error(f"íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. files: {files}")
            return jsonify({'error': 'íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}), 400
        
        # íŒŒì¼ ê°œìˆ˜ ì œí•œ í™•ì¸
        if len(files) > 10:
            return jsonify({'error': 'ìµœëŒ€ 10ê°œì˜ íŒŒì¼ë§Œ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'}), 400
        
        expiration_days = int(request.form.get('expiration_days', 7))
        logger.info(f"ì—…ë¡œë“œ íŒŒì¼ ê°œìˆ˜: {len(files)}, ìœ íš¨ê¸°ê°„: {expiration_days}ì¼")
        
        # ë²„í‚· ì¡´ì¬ í™•ì¸
        if not ensure_bucket_exists():
            return jsonify({'error': 'S3 ë²„í‚· ì„¤ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. AWS ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.'}), 500
        
        uploaded_files = []
        total_size = 0
        
        # ê° íŒŒì¼ ì²˜ë¦¬
        for file in files:
            if file.filename == '':
                continue
                
            logger.info(f"ì²˜ë¦¬ ì¤‘ì¸ íŒŒì¼: {file.filename}")
            
            # íŒŒì¼ í¬ê¸° ê³„ì‚°
            file.seek(0, 2)  # íŒŒì¼ ëìœ¼ë¡œ ì´ë™
            file_size = file.tell()
            file.seek(0)  # íŒŒì¼ ì‹œì‘ìœ¼ë¡œ ë˜ëŒë¦¬ê¸°
            total_size += file_size
            
            logger.info(f"íŒŒì¼ í¬ê¸°: {file_size} bytes")
            
            # íŒŒì¼ ì—…ë¡œë“œ
            uploaded_filename = upload_file_to_s3(file)
            if not uploaded_filename:
                logger.error(f"íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {file.filename}")
                return jsonify({'error': f'íŒŒì¼ "{file.filename}" ì—…ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. S3 ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.'}), 500
            
            logger.info(f"S3 ì—…ë¡œë“œ ì„±ê³µ: {uploaded_filename}")
            
            # Content-Type í™•ì¸
            content_type = mimetypes.guess_type(file.filename)[0] or 'application/octet-stream'
            
            # ë³´ì•ˆ í‚¤ ìƒì„± ë° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
            secure_key = store_file_link(
                uploaded_filename, 
                file.filename, 
                file_size, 
                content_type, 
                expiration_days
            )
            
            if not secure_key:
                logger.error(f"ë³´ì•ˆ ë§í¬ ìƒì„± ì‹¤íŒ¨: {file.filename}")
                return jsonify({'error': f'íŒŒì¼ "{file.filename}"ì˜ ë³´ì•ˆ ë§í¬ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'}), 500
            
            logger.info(f"ë³´ì•ˆ í‚¤ ìƒì„± ì„±ê³µ: {secure_key}")
            
            # ì•ˆì „í•œ ë‹¤ìš´ë¡œë“œ URL ìƒì„±
            download_url = f"{request.host_url}download/{secure_key}"
            
            uploaded_files.append({
                'original_filename': file.filename,
                'uploaded_filename': uploaded_filename,
                'download_url': download_url,
                'secure_key': secure_key,
                'file_size': file_size
            })
        
        # ë§Œë£Œ ì‹œê°„ ê³„ì‚°
        expiry_date = datetime.now() + timedelta(days=expiration_days)
        
        result = {
            'success': True,
            'bucket_name': BUCKET_NAME,
            'region': AWS_REGION,
            'files': uploaded_files,
            'file_count': len(uploaded_files),
            'total_size': total_size,
            'expiry_date': expiry_date.strftime('%Y-%m-%d %H:%M:%S UTC'),
            'expiration_days': expiration_days
        }
        
        logger.info(f"ì—…ë¡œë“œ ì„±ê³µ: {len(uploaded_files)}ê°œ íŒŒì¼")
        return jsonify(result)
        
    except Exception as e:
        logger.error(f"ì—…ë¡œë“œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        logger.error(traceback.format_exc())
        return jsonify({'error': f'ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}), 500

@app.route('/download/<secure_key>')
def download_file(secure_key):
    """ë³´ì•ˆ í‚¤ë¥¼ í†µí•œ í”„ë¡ì‹œ ë‹¤ìš´ë¡œë“œ"""
    try:
        # íŒŒì¼ ì •ë³´ ì¡°íšŒ
        file_info = get_file_info(secure_key)
        if not file_info:
            return "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë§í¬ê°€ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤.", 404
        
        # ë‹¤ìš´ë¡œë“œ íšŸìˆ˜ ì¦ê°€
        increment_download_count(secure_key)
        
        # S3ì—ì„œ íŒŒì¼ ìŠ¤íŠ¸ë¦¬ë°
        try:
            response = s3_client.get_object(Bucket=BUCKET_NAME, Key=file_info['s3_key'])
            
            def generate():
                for chunk in response['Body'].iter_chunks(chunk_size=8192):
                    yield chunk
            
            # í•œê¸€ íŒŒì¼ëª… ì¸ì½”ë”© ì²˜ë¦¬
            from urllib.parse import quote
            encoded_filename = quote(file_info['original_filename'].encode('utf-8'))
            
            # ì‘ë‹µ í—¤ë” ì„¤ì •
            headers = {
                'Content-Type': file_info['content_type'],
                'Content-Disposition': f'attachment; filename*=UTF-8\'\'{encoded_filename}',
                'Content-Length': str(file_info['file_size']),
                'Cache-Control': 'no-cache, no-store, must-revalidate',
                'Pragma': 'no-cache',
                'Expires': '0'
            }
            
            logger.info(f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {secure_key} -> {file_info['original_filename']}")
            
            return Response(
                stream_with_context(generate()),
                headers=headers
            )
            
        except ClientError as e:
            logger.error(f"S3 íŒŒì¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return "íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", 500
            
    except Exception as e:
        logger.error(f"ë‹¤ìš´ë¡œë“œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        logger.error(traceback.format_exc())
        return "ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", 500

@app.route('/file-info/<secure_key>')
def get_file_info_api(secure_key):
    """íŒŒì¼ ì •ë³´ ì¡°íšŒ API (ë‹¤ìš´ë¡œë“œ ì—†ì´)"""
    try:
        file_info = get_file_info(secure_key)
        if not file_info:
            return jsonify({'error': 'íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë§í¬ê°€ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'}), 404
        
        return jsonify({
            'original_filename': file_info['original_filename'],
            'file_size': file_info['file_size'],
            'content_type': file_info['content_type'],
            'expires_at': file_info['expires_at'],
            'download_count': file_info['download_count']
        })
    except Exception as e:
        logger.error(f"íŒŒì¼ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        return jsonify({'error': 'íŒŒì¼ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}), 500

@app.route('/health')
def health_check():
    try:
        # AWS ìê²© ì¦ëª… í™•ì¸
        if not s3_client:
            return jsonify({
                'status': 'unhealthy',
                'error': 'AWS ìê²© ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
                'bucket': BUCKET_NAME,
                'region': AWS_REGION
            }), 500
        
        # ë²„í‚· ì ‘ê·¼ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        s3_client.head_bucket(Bucket=BUCKET_NAME)
        
        return jsonify({
            'status': 'healthy',
            'bucket': BUCKET_NAME,
            'region': AWS_REGION
        })
    except ClientError as e:
        return jsonify({
            'status': 'unhealthy',
            'error': str(e),
            'bucket': BUCKET_NAME,
            'region': AWS_REGION
        }), 500
    except Exception as e:
        return jsonify({
            'status': 'unhealthy',
            'error': f'ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}',
            'bucket': BUCKET_NAME,
            'region': AWS_REGION
        }), 500

@app.route('/bucket-info')
def bucket_info():
    """ë²„í‚· ì •ë³´ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        if not s3_client:
            return jsonify({
                'bucket_name': BUCKET_NAME,
                'region': AWS_REGION,
                'exists': False,
                'error': 'AWS ìê²© ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
            })
        
        # ë²„í‚· ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        s3_client.head_bucket(Bucket=BUCKET_NAME)
        
        # ë²„í‚· ë‚´ ê°ì²´ ìˆ˜ í™•ì¸ (ìµœëŒ€ 1000ê°œê¹Œì§€)
        response = s3_client.list_objects_v2(Bucket=BUCKET_NAME, MaxKeys=1000)
        object_count = response.get('KeyCount', 0)
        
        return jsonify({
            'bucket_name': BUCKET_NAME,
            'region': AWS_REGION,
            'exists': True,
            'object_count': object_count
        })
    except ClientError as e:
        return jsonify({
            'bucket_name': BUCKET_NAME,
            'region': AWS_REGION,
            'exists': False,
            'error': str(e)
        })
    except Exception as e:
        return jsonify({
            'bucket_name': BUCKET_NAME,
            'region': AWS_REGION,
            'exists': False,
            'error': f'ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}'
        })

@app.errorhandler(500)
def internal_error(error):
    logger.error(f"500 ì—ëŸ¬ ë°œìƒ: {error}")
    return jsonify({'error': 'ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}), 500

@app.errorhandler(404)
def not_found(error):
    return jsonify({'error': 'ìš”ì²­í•œ í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404

if __name__ == '__main__':
    print(f"S3 ë²„í‚·: {BUCKET_NAME}")
    print(f"AWS ë¦¬ì „: {AWS_REGION}")
    print("=" * 50)
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
    init_database()
    print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    # ë§Œë£Œëœ ë§í¬ ì •ë¦¬
    cleanup_expired_links()
    
    # AWS ìê²© ì¦ëª… í™•ì¸
    try:
        if s3_client:
            # ê°„ë‹¨í•œ AWS ì—°ê²° í…ŒìŠ¤íŠ¸
            s3_client.list_buckets()
            print("âœ… AWS ìê²© ì¦ëª… í™•ì¸ë¨")
        else:
            print("âŒ AWS ìê²© ì¦ëª… ì„¤ì • í•„ìš”")
    except NoCredentialsError:
        print("âŒ AWS ìê²© ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì •í•˜ì„¸ìš”: aws configure")
    except Exception as e:
        print(f"âš ï¸  AWS ì—°ê²° í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
    
    print("=" * 50)
    print("ğŸ”’ ë³´ì•ˆ ê°•í™”ëœ í”„ë¡ì‹œ ë‹¤ìš´ë¡œë“œ ì‹œìŠ¤í…œ í™œì„±í™”")
    print("ğŸ“Š SQLite ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜ ë§í¬ ê´€ë¦¬")
    print("=" * 50)
    
    # ë°°í¬ í™˜ê²½ì—ì„œëŠ” í™˜ê²½ ë³€ìˆ˜ì—ì„œ í¬íŠ¸ ê°€ì ¸ì˜¤ê¸°
    port = int(os.environ.get('PORT', 8081))
    host = os.environ.get('HOST', '0.0.0.0')
    debug = os.environ.get('FLASK_ENV', 'development') == 'development'
    
    app.run(debug=debug, host=host, port=port)
